{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading true data\n",
      "INFO:root:Loading prediction data\n"
     ]
    }
   ],
   "source": [
    "from baseline_utils import create_dataframes_and_run_baseline, SEED_LIST\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating dataframes for seed 1\n",
      "INFO:root:Creating dataframes for seed 2\n",
      "INFO:root:Creating dataframes for seed 3\n",
      "INFO:root:Creating dataframes for seed 4\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for seed in SEED_LIST:\n",
    "    result = create_dataframes_and_run_baseline(seed)\n",
    "    df_list.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all relevant baseline results\n",
    "And then print them pseudo-latex style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "baseline_list = ['baseline_gender','baseline_letter','baseline_letter2', #'baseline_len',\n",
    "                        'baseline_combo','baseline_combo2', # \"baseline_combo3\"\n",
    "                ]\n",
    "result_dict = defaultdict(lambda:[])\n",
    "for result in tqdm(df_list):\n",
    "    for name, df in zip([\"train\",\"val\",\"test\"],result):\n",
    "        labels=['en','e','empty','er','s']\n",
    "        list_of_scores = []\n",
    "        for baseline in baseline_list:\n",
    "            pred = df[baseline]\n",
    "            true = df.pred_class\n",
    "            f1scores = f1_score(true,pred,average=None,labels=labels)\n",
    "            individual = [100*f for f in f1scores]\n",
    "            micro = 100*f1_score(true,pred,average='micro',labels=['en','e','empty','er','s'])\n",
    "            macro = 100*f1_score(true,pred,average='macro',labels=['en','e','empty','er','s'])\n",
    "\n",
    "            list_of_scores.append(np.array(individual + [micro,macro]))\n",
    "        result_dict[name].append(list_of_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for train\n",
      "baseline_gender & baseline_letter & baseline_letter2 & baseline_combo & baseline_combo2\n",
      "\\en & 90.6 & 76.3 & 87.1 & 93.3 & 96.0 & \\\\\n",
      "\\e & 60.0 & 54.0 & 74.8 & 74.0 & 87.6 & \\\\\n",
      "\\z & 0.0 & 66.5 & 88.6 & 78.2 & 93.3 & \\\\\n",
      "\\er & 0.0 & 0.0 & 43.5 & 60.3 & 82.8 & \\\\\n",
      "\\s & 0.0 & 43.0 & 56.7 & 44.7 & 65.5 & \\\\\n",
      "\\Micro F1 & 65.7 & 66.2 & 81.6 & 81.9 & 91.3 & \\\\\n",
      "\\Macro F1 & 30.1 & 48.0 & 70.2 & 70.1 & 85.0 & \\\\\n",
      "==========\n",
      "Results for val\n",
      "baseline_gender & baseline_letter & baseline_letter2 & baseline_combo & baseline_combo2\n",
      "\\en & 90.3 & 76.1 & 87.2 & 93.4 & 95.6 & \\\\\n",
      "\\e & 59.8 & 55.8 & 75.0 & 73.6 & 87.3 & \\\\\n",
      "\\z & 0.0 & 67.5 & 88.3 & 79.0 & 92.5 & \\\\\n",
      "\\er & 0.0 & 0.0 & 41.1 & 55.6 & 78.6 & \\\\\n",
      "\\s & 0.0 & 39.1 & 49.1 & 41.2 & 55.2 & \\\\\n",
      "\\Micro F1 & 65.1 & 66.4 & 81.1 & 81.5 & 90.3 & \\\\\n",
      "\\Macro F1 & 30.0 & 47.7 & 68.1 & 68.6 & 81.9 & \\\\\n",
      "==========\n",
      "Results for test\n",
      "baseline_gender & baseline_letter & baseline_letter2 & baseline_combo & baseline_combo2\n",
      "\\en & 90.0 & 76.7 & 87.0 & 93.2 & 94.9 & \\\\\n",
      "\\e & 60.1 & 54.4 & 74.7 & 73.5 & 86.4 & \\\\\n",
      "\\z & 0.0 & 67.0 & 88.6 & 78.2 & 92.6 & \\\\\n",
      "\\er & 0.0 & 0.0 & 43.6 & 60.0 & 80.2 & \\\\\n",
      "\\s & 0.0 & 40.7 & 54.0 & 44.7 & 58.5 & \\\\\n",
      "\\Micro F1 & 65.9 & 66.5 & 81.3 & 81.9 & 90.0 & \\\\\n",
      "\\Macro F1 & 30.0 & 47.8 & 69.6 & 69.9 & 82.5 & \\\\\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "baseline_amt = len(baseline_list)\n",
    "seed_amt = len(SEED_LIST)\n",
    "for name in [\"train\",\"val\",\"test\"]:\n",
    "    print(\"Results for\", name)\n",
    "    print(*baseline_list, sep =' & ')\n",
    "    scores = result_dict[name]\n",
    "    list_of_scores = [np.zeros(7) for i in range(baseline_amt)]\n",
    "    for seed_score in scores:\n",
    "        for i in range(baseline_amt):\n",
    "            list_of_scores[i] += seed_score[i]\n",
    "    for i,z in enumerate(['en','e','z','er','s']+['Micro F1','Macro F1']):\n",
    "        print(*['\\\\'+ z]+[round(scores[i]/seed_amt,1) for scores in list_of_scores]+['\\\\\\\\'], sep = ' & ')\n",
    "    print('='*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit99a4c447b1c847dc90b718925c47771c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
