{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sixth-connectivity",
   "metadata": {},
   "source": [
    "## 1. Compute overgeneralisation matrix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "domestic-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append(\"../wiktionary\")\n",
    "from categorise import categorise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-rehabilitation",
   "metadata": {},
   "source": [
    "Step 1: Load the data by categorising model predictions in all epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loose-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(epoch, seed):\n",
    "    \"\"\"Load Wiktionary predictions from hard-coded path file.\n",
    "    \n",
    "    Args:\n",
    "        epoch (int): number from 1 to 25\n",
    "        seed (int): number from 1 to 5\n",
    "    Returns:\n",
    "        tgts is a list of strings that are the suffix classes\n",
    "        prds is a list of strings that are predicted suffix classes\n",
    "    \"\"\"\n",
    "    tgts, prds = [], []\n",
    "    filename = f\"../opennmt/models/seed={seed}_wiktionary/wiktionary/lstms2s_train_pred_{epoch}.txt\"\n",
    "    with open(\"../wiktionary/wiktionary_train.src\", encoding=\"utf-8\") as f_src, \\\n",
    "         open(\"../wiktionary/wiktionary_train.tgt\", encoding=\"utf-8\") as f_tgt, \\\n",
    "         open(filename, encoding=\"utf-8\") as f_prd:\n",
    "        for src, tgt, prd in zip(f_src, f_tgt, f_prd):\n",
    "            category_tgt = categorise(src.strip(), tgt.strip())\n",
    "            category_prd = categorise(src.strip(), prd.strip())\n",
    "            tgts.append(category_tgt)\n",
    "            prds.append(category_prd)\n",
    "    return tgts, prds\n",
    "\n",
    "_, _ = load_data(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complicated-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n"
     ]
    }
   ],
   "source": [
    "overgeneralisation = defaultdict(lambda: defaultdict(lambda : defaultdict(list)))\n",
    "\n",
    "epochs = range(1, 26)\n",
    "for epoch in epochs:\n",
    "    print(f\"Processing epoch {epoch}\")\n",
    "    for seed in [1, 2, 3, 4, 5]:\n",
    "        cats_tgts, cats_prds = load_data(epoch, seed)\n",
    "        for focus_class in [0, 1, 2, 3, 4]:\n",
    "            for overgen_class in [0, 1, 2, 3, 4]:\n",
    "                overgeneralisation[focus_class][overgen_class][seed].append(\n",
    "                    np.mean([y == overgen_class for x, y in zip(cats_tgts, cats_prds) if x == focus_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-hammer",
   "metadata": {},
   "source": [
    "Step 2: Per \"focus\" suffix class, we report how often all other classes were emitted,\n",
    "using the maximum amount over the course of training and the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acoustic-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 97.0 0.0\n",
      "0 1 2.0 1.0\n",
      "0 2 1.0 0.0\n",
      "0 3 0.0 0.0\n",
      "0 4 1.0 0.0\n",
      "1 0 5.0 3.0\n",
      "1 1 97.0 0.0\n",
      "1 2 2.0 1.0\n",
      "1 3 1.0 0.0\n",
      "1 4 2.0 1.0\n",
      "2 0 1.0 0.0\n",
      "2 1 1.0 0.0\n",
      "2 2 98.0 1.0\n",
      "2 3 0.0 0.0\n",
      "2 4 1.0 0.0\n",
      "3 0 0.0 0.0\n",
      "3 1 21.0 6.0\n",
      "3 2 0.0 0.0\n",
      "3 3 98.0 0.0\n",
      "3 4 1.0 0.0\n",
      "4 0 14.000000000000002 4.0\n",
      "4 1 19.0 3.0\n",
      "4 2 8.0 4.0\n",
      "4 3 1.0 0.0\n",
      "4 4 93.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for focus_class in [0, 1, 2, 3, 4]:\n",
    "    for overgen_class in [0, 1, 2, 3, 4]:\n",
    "        maxi = []\n",
    "        for seed in [1, 2, 3, 4, 5]:\n",
    "            maxi.append(max(overgeneralisation[focus_class][overgen_class][seed]))\n",
    "        print(focus_class, overgen_class, round(np.mean(maxi), 2)*100, round(np.std(maxi), 2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-duncan",
   "metadata": {},
   "source": [
    "## 2. Visualise overgeneralisation curves for -s and -er"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-quantity",
   "metadata": {},
   "source": [
    "Step 1: Create functionality to process overgeneralisation numbers for one focus class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "\n",
    "def process_overgeneralisation(focus_class):\n",
    "    \"\"\"\n",
    "    Turn target and prediction classes into overgen % for 25 epochs.\n",
    "    \n",
    "    Args:\n",
    "        tgts (list): plural classes of targets\n",
    "        prds (list): plural classes of predictions\n",
    "        focus_class (int): class for which you want to analyse overgen\n",
    "\n",
    "    Returns:\n",
    "        dict with per plural_class a list of overgen over training\n",
    "    \"\"\"\n",
    "    accuracies = defaultdict(list)\n",
    "    epochs = range(1, 26)\n",
    "    for epoch in epochs:\n",
    "        print(f\"Processing epoch {epoch}\")\n",
    "        per_seed_acc = defaultdict(list)\n",
    "        for seed in [1, 2, 3, 4, 5]:\n",
    "            tgts, prds = load_data(epoch, seed)\n",
    "            for plural_class in range(5):\n",
    "                per_seed_acc[plural_class].append(\n",
    "                    np.mean([y == plural_class for x, y in zip(tgts, prds) if x == focus_class]))\n",
    "        for plural_class in range(5):\n",
    "            accuracies[plural_class].append(np.mean(per_seed_acc[plural_class]))\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-horror",
   "metadata": {},
   "source": [
    "Step 2: Run overgeneralisation for -s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = process_overgeneralisation(4)\n",
    "\n",
    "colours = sns.color_palette(\"Spectral\", 5)\n",
    "colours[2] = \"purple\"\n",
    "epochs = list(range(1, 26))\n",
    "figure = plt.figure(figsize=(4, 4))\n",
    "\n",
    "def sum_lists(lists):\n",
    "    lists = np.matrix(lists).sum(axis=0).squeeze(0).tolist()\n",
    "    return lists[0]\n",
    "\n",
    "for i in range(5):\n",
    "    ax = sns.lineplot(x=epochs, y=sum_lists([accuracies[j] for j in range(i+1)]), color=colours[i])\n",
    "    if i == 0:\n",
    "        plt.fill_between(\n",
    "            epochs, [0 for _ in epochs], accuracies[i], alpha=0.25, color=colours[i], hatch='/')\n",
    "    elif i < 5:\n",
    "        plt.fill_between(\n",
    "            epochs, sum_lists([accuracies[j] for j in range(i)]),\n",
    "            sum_lists([accuracies[j] for j in range(i+1)]), alpha=0.25, color=colours[i], hatch='/')\n",
    "\n",
    "plt.fill_between(\n",
    "    epochs, sum_lists([accuracies[j] for j in range(5)]),\n",
    "    [1 for _ in epochs], alpha=0.25, color=\"grey\", hatch='/')\n",
    "        \n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"% of samples\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(1, 25)\n",
    "plt.text(1.7, 0.9, \"-?\")\n",
    "plt.text(4, 0.55, \"-s\")\n",
    "plt.text(4, 0.18, \"-e\")\n",
    "plt.text(4, 0.31, \"-$\\o$\")\n",
    "plt.text(4, 0.03, \"-(e)n\")\n",
    "ax.set_yticklabels([0, 20, 40, 60, 80, 100])\n",
    "ax.set_xticks([5, 10, 15, 20, 25])\n",
    "plt.savefig(\"figures/overgeneralisation_wiktionary_s.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-privilege",
   "metadata": {},
   "source": [
    "Step 3: Run overgeneralisation for -er."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = process_overgeneralisation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(4, 4))\n",
    "def sum_lists(lists):\n",
    "    lists = np.matrix(lists).sum(axis=0).squeeze(0).tolist()\n",
    "    return lists[0]\n",
    "\n",
    "for i in [1, 3]:\n",
    "    ax = sns.lineplot(x=epochs, y=sum_lists([accuracies[j] for j in range(i+1)]), color=colours[i])\n",
    "    if i == 0:\n",
    "        plt.fill_between(\n",
    "            epochs, [0 for _ in epochs], accuracies[i], alpha=0.25, color=colours[i], hatch='/')\n",
    "    elif i < 5:\n",
    "        plt.fill_between(\n",
    "            epochs, sum_lists([accuracies[j] for j in range(i)]),\n",
    "            sum_lists([accuracies[j] for j in range(i+1)]), alpha=0.25, color=colours[i], hatch='/')\n",
    "\n",
    "plt.fill_between(\n",
    "    epochs, sum_lists([accuracies[j] for j in range(5)]),\n",
    "    [1 for _ in epochs], alpha=0.25, color=\"grey\", hatch='/')\n",
    "        \n",
    "colours = sns.color_palette(\"Spectral\", 5)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"% of samples\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(1, 25)\n",
    "plt.text(1.48, 0.92, \"-?\")\n",
    "plt.text(4, 0.55, \"-er\")\n",
    "plt.text(4, 0.05, \"-e\")\n",
    "ax.set_yticklabels([0, 20, 40, 60, 80, 100])\n",
    "ax.set_xticks([5, 10, 15, 20, 25])\n",
    "plt.savefig(\"figures/overgeneralisation_wiktionary_er.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
